{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Dataset_Generator_kVp130.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KhxG9H_VBQAe",
        "pBn1Yag3EA9w",
        "yXOoOMniKZOD",
        "RncE9phNO9uL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozanryo/air-kerma-hvl-prediction-AI/blob/main/Dataset_Generator_kVp130.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhxG9H_VBQAe"
      },
      "source": [
        "# **Melakukan Mounting Drive**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HecsrXRLKgNw"
      },
      "source": [
        "**Melakukan Pembacaan File Dicom pada Direktori yang ada di Google Drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9KgW5LrA7af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1a3e0b-2031-46af-8caf-9308824ab64c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBn1Yag3EA9w"
      },
      "source": [
        "# **Menginstall Library yang Dibutuhkan**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJs3-yMpCGJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914e0384-6b0c-4a38-b6dd-38bfda922902"
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXOoOMniKZOD"
      },
      "source": [
        "# **Melakukan Import Library yang akan digunakan**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJwpvPOtEkWy"
      },
      "source": [
        "#Pembacaan Dicom\n",
        "import pydicom as dicom\n",
        "import os\n",
        " \n",
        "#Operasi Matematika dan Visualisasi\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from skimage.io import imread\n",
        "from scipy import ndimage\n",
        " \n",
        "# Mengunduh Dataset\n",
        "from google.colab import files\n",
        " \n",
        "#Pengaturan DataFrame dan Visualisasi Dataset\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        " \n",
        "#Preprocessing Dataset dan Membangun Neural Network\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAkpk5ojEXHE"
      },
      "source": [
        "# **Membaca File Dicom pada Suatu Direktori**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk5XwEvjFpXE"
      },
      "source": [
        "PathDicom_130 = '/content/drive/My Drive/Data/Image/Recap/Part 1/130 kVp'\n",
        "lstFileDicom_130 = [] #Create an Empty List\n",
        "for dirName, subdirlist, filelist in os.walk(PathDicom_130):\n",
        "  for filename in filelist:\n",
        "    if '.dcm' in filename.lower():\n",
        "      lstFileDicom_130.append(os.path.join(dirName, filename))\n",
        " \n",
        "# Get ref file\n",
        "RefDs = dicom.read_file(lstFileDicom_130[0])\n",
        " \n",
        "# Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
        "ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFileDicom_130))\n",
        " \n",
        "# Load spacing values (in mm)\n",
        "ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))\n",
        " \n",
        "# The array is sized based on 'ConstPixelDims'\n",
        "ArrayDicom_130 = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n",
        " \n",
        "# loop through all the DICOM files\n",
        "for filenameDCM_130 in lstFileDicom_130:\n",
        "    # read the file\n",
        "    ds = dicom.read_file(filenameDCM_130)\n",
        "    \n",
        "    # store the raw image data\n",
        "    ArrayDicom_130[:, :,lstFileDicom_130.index(filenameDCM_130)] = ds.pixel_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MUbAKan29Zg"
      },
      "source": [
        "# **Membuat Fungsi Tambahan**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhElhy_u28lQ"
      },
      "source": [
        "#Membuat fungsi untuk Pengambilan Gambar dengan Koordinat utama pada tengah Image\n",
        "def crop_center(img, cropx, cropy):\n",
        "  y,x = img.shape\n",
        "  startx = x//2-(cropx//2)\n",
        "  starty = y//2-(cropy//2)    \n",
        "  return img[starty:starty+cropy,startx:startx+cropx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKMmy5lW3RHw"
      },
      "source": [
        "#Membuat fungsi untuk Pengambilan Gambar dengan Koordinat utama pada titik paling kiri dan paling atas\n",
        "def crop_for_iterate(img, xcrop, ycrop, j, k):\n",
        "  y, x = img.shape\n",
        "  startx = 0 + j*xcrop\n",
        "  starty = 0 + k*ycrop    \n",
        "  cropx = startx + xcrop\n",
        "  cropy = starty + ycrop\n",
        "  return img[starty:cropy, startx:cropx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKXH-I3N3Wym"
      },
      "source": [
        "def multiply_array(arr, n):\n",
        "    result = np.zeros(shape=(n*len(arr), 1))\n",
        " \n",
        "    idx = 0\n",
        "    for _ in range(n):\n",
        "      for element in arr:\n",
        "        result[idx, 0] = element\n",
        "        idx += 1\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7BOdNiM3gnO"
      },
      "source": [
        "def combine_array(arr_1, arr_2, arr_3):\n",
        "    result = np.zeros(shape=((len(arr_1)+ len(arr_2) + len(arr_3)),1))\n",
        " \n",
        "    idx = 0\n",
        "    for element in arr_1:\n",
        "      result[idx, 0] = element\n",
        "      idx+=1\n",
        "    for element in arr_2:\n",
        "      result[idx, 0] = element\n",
        "      idx+=1\n",
        "    for element in arr_3:\n",
        "      result[idx, 0] = element\n",
        "      idx+=1\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RncE9phNO9uL"
      },
      "source": [
        "# **Melakukan Pengambilan Fitur menggunakan Teknik GLCM dan Membangun Dataset**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfVAtBMC2kAQ"
      },
      "source": [
        "def Data_80(start_angle, final_angle, center_crop, crop_iterate, strides):\n",
        "  homogen_80 = []\n",
        "  korelasi_80 = []\n",
        "  dissimilar_80 = []\n",
        "  energi_80 = []\n",
        "  contrast_80 = []\n",
        "  asm_80 = []\n",
        "\n",
        "  dcm_files = ArrayDicom_130.shape[2]\n",
        "  total_angles = final_angle - start_angle\n",
        "\n",
        "  ## For Phantom image that take from 80 kVp\n",
        "  for i in range(dcm_files):\n",
        "    img_80 = ArrayDicom_130[:, :, i]\n",
        " \n",
        "    for l in range(int(start_angle), int(final_angle)): \n",
        "      rot_img_80 = ndimage.rotate(img_80, l)\n",
        "      crop_utama_80 = crop_center(rot_img_80, center_crop, center_crop)\n",
        " \n",
        "      for j in range(int(center_crop/strides)):\n",
        "        for k in range(int(center_crop/strides)):            \n",
        "          crop_80 = crop_for_iterate(crop_utama_80, crop_iterate, crop_iterate, j, k)\n",
        " \n",
        "          glcm_80 = greycomatrix(crop_80, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], 2048, symmetric=True, normed=True)\n",
        "    \n",
        "          homogen_80.append(greycoprops(glcm_80, 'homogeneity')[0, 0])\n",
        "          korelasi_80.append(greycoprops(glcm_80, 'correlation')[0, 0])\n",
        "          dissimilar_80.append(greycoprops(glcm_80, 'dissimilarity')[0, 0])\n",
        "          energi_80.append(greycoprops(glcm_80, 'energy')[0, 0])\n",
        "          contrast_80.append(greycoprops(glcm_80, 'contrast')[0, 0])\n",
        "          asm_80.append(greycoprops(glcm_80, 'ASM')[0, 0])\n",
        "  \n",
        "  #Penempatan Hasil Pengukuran Fitur GLCM \n",
        "  hom = np.asarray(homogen_80)\n",
        "  kor = np.asarray(korelasi_80)\n",
        "  diss = np.asarray(dissimilar_80)\n",
        "  energi = np.asarray(energi_80)\n",
        "  con = np.asarray(contrast_80)\n",
        "  asm = np.asarray(asm_80)\n",
        " \n",
        "  Dataset = [hom, kor, diss, energi, con, asm]\n",
        "  Dataset = np.asarray(Dataset)\n",
        "  Dataset = np.transpose(Dataset)\n",
        " \n",
        "  #Penempatan Hasil Pengukuran Hasil Eksperimen\n",
        "  kVp_80 = np.asarray([130])\n",
        "  Kerma_80 = np.asarray([2])\n",
        "  HVL_80 = np.asarray([2])\n",
        " \n",
        "  kVp_80 = multiply_array(kVp_80, int(((center_crop/strides)*(center_crop/strides))*total_angles*dcm_files))\n",
        "  Kerma_80 = multiply_array(Kerma_80, int(((center_crop/strides)*(center_crop/strides))*total_angles*dcm_files))\n",
        "  HVL_80 = multiply_array(HVL_80, int(((center_crop/strides)*(center_crop/strides))*total_angles*dcm_files))\n",
        "\n",
        "  kVp = np.asarray(kVp_80)\n",
        " \n",
        "  Kerma = np.asarray(Kerma_80)\n",
        " \n",
        "  HVL = np.asarray(HVL_80)\n",
        " \n",
        "  Dataset = np.append(Dataset, kVp, axis=1)\n",
        "  Dataset = np.append(Dataset, Kerma, axis=1)\n",
        "  Dataset = np.append(Dataset, HVL, axis=1)\n",
        " \n",
        "  Dataset = pd.DataFrame({'Homogeneity': Dataset[:,0], \n",
        "                          'Correlation': Dataset[:,1], \n",
        "                          'Dissimilarity': Dataset[:,2], \n",
        "                          'Energy': Dataset[:,3],\n",
        "                          'Contrast': Dataset[:,4],\n",
        "                          'ASM': Dataset[:,5], \n",
        "                          'Nilai kVp': Dataset[:,6], \n",
        "                          'Kerma Udara (uGy/mAs)': Dataset[:,7],\n",
        "                          'Half Value Layer (mmAl)': Dataset[:,8]})\n",
        "  \n",
        "  return Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts99E79cSbfm"
      },
      "source": [
        "Fungsi diatas baru dapat dilakukan pada :\n",
        "\n",
        "1. Window Center 50 x 50 \n",
        "2. Window Iterate 10 x 10\n",
        "3. stride 10, 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKBYxhMwllaU"
      },
      "source": [
        "# **Hasil Pengukuran**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUDQp8FP1yGz"
      },
      "source": [
        "A = Data_80(start_angle=315, \n",
        "            final_angle=360, \n",
        "            center_crop=50, \n",
        "            crop_iterate=10, \n",
        "            strides=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0kbvy19EzYg"
      },
      "source": [
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-jA_YK009vJ"
      },
      "source": [
        "# **Mengunduh Dataset**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFo98saK1BqN"
      },
      "source": [
        "with pd.ExcelWriter('Data130_part1(315, 360).xlsx') as writer:\n",
        "     A.to_excel(writer, sheet_name='Sheet', index=False)\n",
        " \n",
        "files.download('Data130_part1(315, 360).xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}